---
title: "Unity GPU Jobs Analytics Report"
format: 
  html:
    theme: cosmo
    css: styles.css
    toc: true
    toc-depth: 3
    page-layout: article
    self-contained: true
params:
  data_file: "user_data.json"
---

```{python}
#| tags: [parameters]
#| echo: false

data_file = "user_data.json"
```

```{python}
#| echo: false
#| output: asis

# Import required libraries
import pandas as pd
import numpy as np
import json
import sys
import os
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# Add the project root to Python path so we can import from src
project_root = Path.cwd().parent  # Go up from reports directory to project root
sys.path.insert(0, str(project_root))

# Set up plotting style
plt.style.use('default')
sns.set_palette("husl")

# Load data from JSON file
try:
    # Check if we're in test mode (data_file exists in current directory)
    if os.path.exists(data_file):
        # Test mode: use direct path
        json_path = data_file
    else:
        # Production mode: use temp directory
        json_path = f"user_reports/temp/{data_file}"
    
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    # Extract all variables from the JSON data
    user_id = data['user_id']
    start_date = data['start_date']
    end_date = data['end_date']
    analysis_period = data['analysis_period']
    
    # Convert data back to DataFrames
    summary_stats_df = pd.DataFrame(data['summary_stats'])
    comparison_stats_df = pd.DataFrame(data['comparison_stats'])
    time_series_data_df = pd.DataFrame(data['time_series_data'])
    gpu_type_data_df = pd.DataFrame(data['gpu_type_data'])
    recommendations = data['recommendations']
    user_jobs = pd.DataFrame(data['user_jobs'])
    
    print(f"Report generated for user: **{user_id}**")
    print()
    print(f"Analysis period: **{analysis_period}**")
    print()
    print(f"Total jobs analyzed: {len(user_jobs)}")
    
except Exception as e:
    print(f"Error loading data: {e}")
    # Initialize fallback values
    user_id = "UNKNOWN"
    analysis_period = "Unknown"
    summary_stats_df = pd.DataFrame()
    comparison_stats_df = pd.DataFrame()
    time_series_data_df = pd.DataFrame()
    gpu_type_data_df = pd.DataFrame()
    recommendations = []
    user_jobs = pd.DataFrame()
```

```{python}
#| echo: false
#| output: asis

# Set the document title dynamically
from IPython.display import display, HTML
title_html = f"""
<script>
document.title = 'Unity GPU Jobs Analytics Report - {user_id}';
</script>
"""
display(HTML(title_html))
```

---

### Performance Summary

```{python}
#| echo: false
#| output: asis

if len(summary_stats_df) > 0:
    # Extract key metrics from summary_stats_df for narrative
    try:
        # Get efficiency category and metrics from the table
        efficiency_row = summary_stats_df[summary_stats_df['Metric'].str.contains('efficiency category', case=False, na=False)]
        vram_usage_row = summary_stats_df[summary_stats_df['Metric'].str.contains('Average VRAM efficiency', case=False, na=False)]
        zero_usage_row = summary_stats_df[summary_stats_df['Metric'].str.contains('Zero usage jobs', case=False, na=False)]
        time_estimate_row = summary_stats_df[summary_stats_df['Metric'].str.contains('Time estimation', case=False, na=False)]
        cpu_gpu_ratio_row = summary_stats_df[summary_stats_df['Metric'].str.contains('CPU/GPU memory ratio', case=False, na=False)]
        
        # Generate narrative based on available data
        if not efficiency_row.empty:
            efficiency_category = efficiency_row.iloc[0]['Value']
            print(f"Your overall job's efficiency in this period lies in the **{efficiency_category}** category.")
        
        if not vram_usage_row.empty:
            vram_efficiency = vram_usage_row.iloc[0]['Value']
            print(f" Your GPU jobs use **{vram_efficiency}** of the requested GPU memory on average.")
        
        if not zero_usage_row.empty:
            zero_usage = zero_usage_row.iloc[0]['Value']
            if "0" not in str(zero_usage):
                print(f"\n⚠️ **{zero_usage}** of your jobs did not use any significant amount of GPU memory.")
            else:
                print("\n✓ All of your jobs are using GPU memory effectively.")
        
        if not time_estimate_row.empty:
            time_estimate = time_estimate_row.iloc[0]['Value']
            print(f"\nYou appear to have **{time_estimate}** the time limits for your jobs.")
        
        if not cpu_gpu_ratio_row.empty:
            cpu_gpu_ratio = cpu_gpu_ratio_row.iloc[0]['Value']
            try:
                ratio_value = float(str(cpu_gpu_ratio).split()[0])
                if ratio_value > 2.0:
                    print(f"\n⚠️ Your CPU to GPU memory usage ratio is high ({cpu_gpu_ratio}). This might indicate that your jobs are more CPU-intensive than GPU-intensive.")
            except:
                pass
                
    except Exception as e:
        print("Performance analysis data not available in expected format.")
else:
    print("No performance summary data provided.")
```

---

## Main GPU Usage Analysis

### Memory Usage Recommendations

```{python}
#| echo: false
#| output: asis

# Display relevant recommendations for GPU memory usage
if recommendations and len(recommendations) > 0:
    memory_recommendations = [rec for rec in recommendations if any(word in rec.lower() for word in ['memory', 'vram', 'gpu', 'efficiency'])]
    if memory_recommendations:
        print("💡 **Key recommendations for optimizing your GPU memory usage:**\n")
        for i, rec in enumerate(memory_recommendations[:3], 1):  # Show top 3 relevant recommendations
            print(f"{i}. {rec}\n")
    else:
        print("💡 **General Tip:** Monitor your GPU memory efficiency to optimize resource usage and reduce costs.\n")
else:
    print("💡 **General Tip:** Focus on optimizing GPU memory usage and time allocation for better efficiency.\n")
```

### GPU Memory Usage, Job Status and GPU Type Distribution

```{python}
#| echo: false
#| fig-cap: "GPU Memory Usage, Job Status and GPU Type Distribution"
#| fig-width: 14
#| fig-height: 10

if len(user_jobs) > 0:
    from src.visualization.columns import ColumnVisualizer
    
    # Check which columns are available and build the columns list dynamically
    columns_to_plot = []
    
    # Check for GPU Memory Usage (requires used_vram_gib)
    if 'used_vram_gib' in user_jobs.columns:
        columns_to_plot.append('GPUMemUsage')
    
    # Check for GPU Type
    if 'GPUType' in user_jobs.columns:
        columns_to_plot.append('GPUType')
    
    # Check for Job Status
    if 'Status' in user_jobs.columns:
        columns_to_plot.append('Status')
    
    # Only visualize if we have at least one column to plot
    if columns_to_plot:
        # Initialize the visualizer with the user's job data
        visualizer = ColumnVisualizer(user_jobs)
        
        # Use the visualize method to generate visualizations for available columns
        visualizer.visualize(output_dir_path=None, columns=columns_to_plot, generate_statistics=False)
    else:
        print("No visualizable columns (GPUMemUsage, GPUType, Status) are available in the data.")
else:
    print("No job data available for visualization.")
```

---

<div style="margin: 40px 0; padding: 20px; background-color: #f8f9fa; border-radius: 8px; border-left: 4px solid #007bff;">
<h4 style="color: #007bff; margin-bottom: 10px;">💡 Understanding Your GPU Usage</h4>
<p>The above visualization shows your GPU memory usage patterns, job statuses, and GPU types used. This data helps identify optimization opportunities and resource allocation patterns.</p>
</div>

---

<details>
<summary><h2 style="display: inline-block; margin: 0;">📊 Additional Analysis & Plots</h2></summary>

## A100 GPU Analysis

```{python}
#| echo: false
#| output: asis

# Check if user has used A100 GPUs
def extract_gpu_type(gpu_type_val):
    """Extract GPU type from various data formats."""
    if isinstance(gpu_type_val, list) and len(gpu_type_val) > 0:
        return gpu_type_val[0]
    elif isinstance(gpu_type_val, dict) and len(gpu_type_val) > 0:
        return list(gpu_type_val.keys())[0]
    elif isinstance(gpu_type_val, str):
        return gpu_type_val
    else:
        return "unknown"

if len(user_jobs) > 0 and 'GPUType' in user_jobs.columns:
    # Extract primary GPU types
    user_jobs_a100 = user_jobs.copy()
    user_jobs_a100['primary_gpu_type'] = user_jobs_a100['GPUType'].apply(extract_gpu_type)
    
    # Filter for A100 jobs
    a100_jobs = user_jobs_a100[user_jobs_a100['primary_gpu_type'].str.contains('a100', case=False, na=False)]
    
    if len(a100_jobs) > 0:
        a100_percentage = (len(a100_jobs) / len(user_jobs)) * 100
        print(f"## A100 GPU Usage Analysis")
        print(f"You have used A100 GPUs in **{len(a100_jobs)}** out of **{len(user_jobs)}** jobs ({a100_percentage:.1f}%).")
        print()
    else:
        print("You have not used A100 GPUs in any of your analyzed jobs. This section is not applicable.")
        a100_jobs = pd.DataFrame()  # Set empty for conditional sections below
else:
    print("GPU type data not available for A100 analysis.")
    a100_jobs = pd.DataFrame()
```

### A100 vs Other GPU Performance Comparison

```{python}
#| echo: false
#| fig-cap: "A100 vs Other GPU Performance"
#| fig-width: 12
#| fig-height: 8

if len(a100_jobs) > 0 and len(user_jobs) > 0:
    try:
        # Create comparison between A100 and other GPUs
        user_jobs_comparison = user_jobs.copy()
        user_jobs_comparison['primary_gpu_type'] = user_jobs_comparison['GPUType'].apply(extract_gpu_type)
        user_jobs_comparison['is_a100'] = user_jobs_comparison['primary_gpu_type'].str.contains('a100', case=False, na=False)
        user_jobs_comparison['gpu_category'] = user_jobs_comparison['is_a100'].map({True: 'A100', False: 'Other GPUs'})
        
        # Calculate efficiency metrics by GPU category
        efficiency_metrics = user_jobs_comparison.groupby('gpu_category').agg({
            'alloc_vram_efficiency': 'mean' if 'alloc_vram_efficiency' in user_jobs_comparison.columns else lambda x: 0,
            'used_vram_gib': 'mean',
            'allocated_vram': 'mean',
            'job_hours': 'mean',
            'JobID': 'count'
        }).reset_index()
        
        if len(efficiency_metrics) > 1:  # Both A100 and other GPUs present
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))

            # 1. VRAM Efficiency Comparison
            ax1.bar(efficiency_metrics['gpu_category'], efficiency_metrics['alloc_vram_efficiency'],
                   color=['#FF6B6B', '#4ECDC4'], alpha=0.8)
            ax1.set_title('Average VRAM Efficiency')
            ax1.set_ylabel('Efficiency')
            # Set y-axis limit higher to show labels
            # Set y-axis limit higher to show labels
            max_val = max(efficiency_metrics['alloc_vram_efficiency'])
            ax1.set_ylim(0, max_val * 1.15)
            ax1.set_ylim(0, max_val * 1.15)
            for i, v in enumerate(efficiency_metrics['alloc_vram_efficiency']):
                ax1.text(i, v + max_val * 0.02, f'{v:.3f}',
                        ha='center', va='bottom', fontweight='bold')

            # 2. Memory Usage Comparison
            ax2.bar(efficiency_metrics['gpu_category'], efficiency_metrics['used_vram_gib'],
                   color=['#FF6B6B', '#4ECDC4'], alpha=0.8)
            ax2.set_title('Average GPU Memory Used')
            # Set y-axis limit higher to show labels
            ax2.set_ylabel('Memory (GiB)')
            ax2.set_ylim(0, max_val * 1.15)
            max_val = max(efficiency_metrics['used_vram_gib'])
            ax2.set_ylim(0, max_val * 1.15)
            for i, v in enumerate(efficiency_metrics['used_vram_gib']):
                ax2.text(i, v + max_val * 0.02, f'{v:.1f}',
                        ha='center', va='bottom', fontweight='bold')

            # 3. Job Duration Comparison
            ax3.bar(efficiency_metrics['gpu_category'], efficiency_metrics['job_hours'],
                   color=['#FF6B6B', '#4ECDC4'], alpha=0.8)
            # Set y-axis limit higher to show labels
            ax3.set_title('Average Job Duration')
            ax3.set_ylim(0, max_val * 1.15)
            # Set y-axis limit higher to show labels
            max_val = max(efficiency_metrics['job_hours'])
            ax3.set_ylim(0, max_val * 1.15)
            for i, v in enumerate(efficiency_metrics['job_hours']):
                ax3.text(i, v + max_val * 0.02, f'{v:.1f}',
                        ha='center', va='bottom', fontweight='bold')

            # 4. Job Count
            ax4.bar(efficiency_metrics['gpu_category'], efficiency_metrics['JobID'],
            # Set y-axis limit higher to show labels
                   color=['#FF6B6B', '#4ECDC4'], alpha=0.8)
            ax4.set_ylim(0, max_val * 1.15)
            ax4.set_ylabel('Job Count')
            # Set y-axis limit higher to show labels
            max_val = max(efficiency_metrics['JobID'])
            ax4.set_ylim(0, max_val * 1.15)
            for i, v in enumerate(efficiency_metrics['JobID']):
                ax4.text(i, v + max_val * 0.02, f'{int(v)}',
                        ha='center', va='bottom', fontweight='bold')

            plt.tight_layout()
            plt.show()
        else:
            print("Only one GPU type category available - comparison not possible.")
            
    except Exception as e:
        print(f"Error creating A100 comparison: {e}")
else:
    print("A100 comparison not available - insufficient A100 usage data.")
```

---

<div style="margin: 30px 0; padding: 15px; background-color: #fff3cd; border-radius: 6px; border-left: 4px solid #ffc107;">
<h5 style="color: #856404; margin-bottom: 8px;">📊 A100 Performance Analysis</h5>
<p style="margin-bottom: 0;">A100 GPUs are high-performance resources. The following distribution analysis helps understand how effectively you're utilizing these premium GPUs.</p>
</div>

---

### A100 Efficiency Distribution

```{python}
#| echo: false
#| fig-cap: "A100 VRAM Efficiency Distribution"
#| fig-width: 10
#| fig-height: 6

if len(a100_jobs) > 0 and 'alloc_vram_efficiency' in a100_jobs.columns:
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Histogram of A100 efficiency
        ax1.hist(a100_jobs['alloc_vram_efficiency'], bins=20, alpha=0.7, color='#FF6B6B', edgecolor='black')
        ax1.axvline(a100_jobs['alloc_vram_efficiency'].mean(), color='red', linestyle='--', 
                   label=f'Mean: {a100_jobs["alloc_vram_efficiency"].mean():.3f}')
        ax1.axvline(a100_jobs['alloc_vram_efficiency'].median(), color='orange', linestyle='--',
                   label=f'Median: {a100_jobs["alloc_vram_efficiency"].median():.3f}')
        ax1.set_xlabel('VRAM Efficiency')
        ax1.set_ylabel('Number of A100 Jobs')
        ax1.set_title('Distribution of A100 VRAM Efficiency')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Efficiency over time for A100 jobs
        if 'StartTime' in a100_jobs.columns:
            a100_sorted = a100_jobs.sort_values('StartTime')
            ax2.scatter(a100_sorted['StartTime'], a100_sorted['alloc_vram_efficiency'], 
                       alpha=0.6, color='#FF6B6B', s=50)
            ax2.set_xlabel('Date')
            ax2.set_ylabel('VRAM Efficiency')
            ax2.set_title('A100 Job Efficiency Over Time')
            ax2.grid(True, alpha=0.3)
            
            # Add trend line
            if len(a100_sorted) > 1:
                from scipy import stats
                x_numeric = pd.to_numeric(pd.to_datetime(a100_sorted['StartTime']))
                slope, intercept, r_value, p_value, std_err = stats.linregress(x_numeric, a100_sorted['alloc_vram_efficiency'])
                line = slope * x_numeric + intercept
                ax2.plot(a100_sorted['StartTime'], line, 'r-', alpha=0.8, 
                        label=f'Trend (R²={r_value**2:.3f})')
                ax2.legend()
        else:
            ax2.text(0.5, 0.5, 'No timestamp data available', ha='center', va='center', transform=ax2.transAxes)
            ax2.set_title('A100 Timeline Not Available')
        
        plt.tight_layout()
        plt.show()
        
    except Exception as e:
        print(f"Error creating A100 efficiency distribution: {e}")
        # Simple fallback
        print(f"A100 jobs summary:")
        print(f"- Total A100 jobs: {len(a100_jobs)}")
        if 'alloc_vram_efficiency' in a100_jobs.columns:
            print(f"- Average efficiency: {a100_jobs['alloc_vram_efficiency'].mean():.3f}")
            print(f"- Efficiency range: {a100_jobs['alloc_vram_efficiency'].min():.3f} - {a100_jobs['alloc_vram_efficiency'].max():.3f}")
else:
    print("A100 efficiency distribution not available - insufficient data.")
```

### A100 Usage Insights

```{python}
#| echo: false
#| output: asis

if len(a100_jobs) > 0:
    # Calculate A100-specific insights
    try:
        total_a100_hours = a100_jobs['job_hours'].sum() if 'job_hours' in a100_jobs.columns else 0
        avg_a100_efficiency = a100_jobs['alloc_vram_efficiency'].mean() if 'alloc_vram_efficiency' in a100_jobs.columns else 0
        avg_a100_memory = a100_jobs['used_vram_gib'].mean() if 'used_vram_gib' in a100_jobs.columns else 0
        a100_allocated_memory = a100_jobs['allocated_vram'].mean() if 'allocated_vram' in a100_jobs.columns else 0
        
        print("### Key A100 Insights")
        print()
        print(f"**A100 Resource Usage:**")
        print()
        print(f"- Total A100 GPU hours consumed: **{total_a100_hours:.1f} hours**")
        print(f"- Average memory utilization: **{avg_a100_memory:.1f} GiB** out of **{a100_allocated_memory:.1f} GiB** allocated")
        print(f"- Average VRAM efficiency: **{avg_a100_efficiency:.1%}**")
        print()
        
        # Efficiency assessment
        if avg_a100_efficiency < 0.2:
            efficiency_assessment = "**Low** - Consider if A100s are necessary for your workloads"
            efficiency_color = "🔴"
        elif avg_a100_efficiency < 0.5:
            efficiency_assessment = "**Moderate** - Room for improvement in memory utilization"
            efficiency_color = "🟡"
        else:
            efficiency_assessment = "**Good** - Efficient use of A100 resources"
            efficiency_color = "🟢"
        
        print(f"**A100 Efficiency Assessment:** {efficiency_color} {efficiency_assessment}")
        print()
        
        # Cost implications (approximate)
        if total_a100_hours > 0:
            # A100s are typically 4-8x more expensive than other GPUs
            other_jobs = user_jobs[~user_jobs.index.isin(a100_jobs.index)] if len(user_jobs) > len(a100_jobs) else pd.DataFrame()
            if len(other_jobs) > 0:
                other_hours = other_jobs['job_hours'].sum() if 'job_hours' in other_jobs.columns else 0
                a100_ratio = total_a100_hours / (total_a100_hours + other_hours) if other_hours > 0 else 1
                print(f"**Resource Distribution:**")
                print()
                print(f"- A100 hours: {total_a100_hours:.1f} ({a100_ratio:.1%} of total GPU hours)")
                print(f"- Other GPU hours: {other_hours:.1f} ({1-a100_ratio:.1%} of total GPU hours)")
                print()
        
        # Recommendations based on usage pattern
        print("**A100-Specific Recommendations:**")
        print()
        
        if avg_a100_efficiency < 0.3:
            print("- 🔧 **Optimize Memory Usage**: Your A100 efficiency is low. Consider using batch size optimization or mixed precision training.")
            print("- 🔄 **Consider Alternatives**: For jobs with low memory requirements, regular GPUs might be more cost-effective.")
        
        if avg_a100_memory < 20:  # Less than 20GB average usage
            print("- 📊 **Memory Underutilization**: You're using less than half of A100's memory capacity. Consider larger models or batch sizes.")
        
        if len(a100_jobs) < 5:
            print("- 📈 **Limited A100 Experience**: Consider experimenting with larger workloads that can fully utilize A100 capabilities.")
        else:
            print("- ✅ **Regular A100 User**: You're making good use of A100 resources. Continue optimizing for better efficiency.")
            
    except Exception as e:
        print(f"Error generating A100 insights: {e}")
        print("A100 insights could not be generated due to data processing issues.")
else:
    print("No A100 usage insights available.")
```

---

## ROC Efficiency Analysis

```{python}
#| echo: false
#| output: asis

# Check if we have job metrics data for ROC analysis
all_users_job_metrics = data.get('all_users_job_metrics', None)
user_jobs_df = pd.DataFrame(data['user_jobs'])

if all_users_job_metrics is not None and len(all_users_job_metrics) > 100:
    print("### ROC Analysis: VRAM Efficiency Performance")
    print()
    print(f"**User**: {user_id}")
    print(f"**Total jobs in system**: {len(all_users_job_metrics):,}")
    print(f"**Your jobs**: {len(user_jobs_df)}")
    print()
    print("This analysis compares your VRAM efficiency performance against other users in the system.")
    print()
else:
    print("### ROC Analysis Not Available")
    print()
    if all_users_job_metrics is None:
        print("**Reason**: No job metrics data available")
    else:
        print(f"**Reason**: Insufficient job metrics data (need >100, have {len(all_users_job_metrics)})")
    print()
    print("*ROC analysis requires sufficient job data with calculated efficiency metrics.*")
```


## Advanced ROC Analysis (Multiple Users Comparison)

```{python}
#| echo: false
#| fig-cap: "Advanced ROC: Your Performance vs Other Users"
#| fig-width: 14
#| fig-height: 8

# Advanced ROC analysis using the actual ROCVisualizer class
all_users_job_metrics = data.get('all_users_job_metrics', None)

if all_users_job_metrics is not None and len(all_users_job_metrics) > 100 and len(user_jobs_df) > 5:
    try:
        # Import the ROC analyzer for real-time analysis
        import matplotlib.pyplot as plt
        import pandas as pd
        import numpy as np
        from src.analysis.roc_plot import ROCVisualizer
        from src.config.enum_constants import ProportionMetricsEnum, JobEfficiencyMetricsEnum
        
        print("### Advanced ROC Analysis: Your Performance vs Other Users")
        print()
        
        # Convert job metrics to DataFrame - this already has efficiency calculations
        all_jobs_df = pd.DataFrame(all_users_job_metrics)
        
        # Verify we have the required columns
        required_cols = ['User', 'alloc_vram_efficiency']
        missing_cols = [col for col in required_cols if col not in all_jobs_df.columns]
        
        if missing_cols:
            print(f"**Error**: Missing required columns: {missing_cols}")
            print("ROC analysis requires job data with calculated efficiency metrics.")
        else:
            print(f"**Total jobs with metrics**: {len(all_jobs_df):,}")
            print(f"**Your jobs**: {len(user_jobs_df)}")
            
            # Get unique users for comparison
            all_users = all_jobs_df['User'].unique()
            other_users = [u for u in all_users if u != user_id]
            
            if len(other_users) >= 5:
                # Sample users for comparison to avoid overcrowding the plot
                comparison_users = other_users[:20] if len(other_users) > 20 else other_users
                plot_users = [user_id] + comparison_users
                
                print(f"**Comparing against**: {len(comparison_users)} other users")
                print()
                
                # Initialize ROC analyzer with the jobs data (already has metrics calculated)
                roc_instance = ROCVisualizer(jobs_df=all_jobs_df)
                
                # Create the ROC plot
                print("**Creating ROC comparison plot...**")
                fig, axes = roc_instance.multiple_line_roc_plot(
                    plot_object_list=plot_users,
                    object_column_type=ProportionMetricsEnum.USERS,
                    threshold_metric=JobEfficiencyMetricsEnum.ALLOC_VRAM_EFFICIENCY,
                    proportion_metric=ProportionMetricsEnum.JOBS,
                    min_threshold=0.0,
                    max_threshold=1.0,
                    threshold_step=0.01,
                    plot_percentage=True,
                    title=f"ROC Analysis: {user_id} vs Other Users"
                )
                
                plt.show()
                
                # Performance insights
                if 'alloc_vram_efficiency' in user_jobs_df.columns:
                    user_efficiency = user_jobs_df['alloc_vram_efficiency'] * 100
                    system_efficiency = all_jobs_df['alloc_vram_efficiency'] * 100
                    other_users_efficiency = all_jobs_df[all_jobs_df['User'] != user_id]['alloc_vram_efficiency'] * 100
                    
                    print(f"\n**Performance Analysis:**")
                    print()
                    print(f"- **Your average efficiency**: {user_efficiency.mean():.1f}%")
                    print(f"- **System average efficiency**: {system_efficiency.mean():.1f}%")
                    print(f"- **Other users average**: {other_users_efficiency.mean():.1f}%")
                    
                    # Performance comparison
                    if user_efficiency.mean() > other_users_efficiency.mean():
                        performance = "🟢 **Above Average** - You're performing better than other users!"
                    elif user_efficiency.mean() > other_users_efficiency.mean() * 0.9:
                        performance = "🟡 **Near Average** - You're close to other users' performance."
                    else:
                        performance = "🔴 **Below Average** - There's room for improvement."
                    
                    print(f"- **Performance**: {performance}")
                    
                    # Efficiency distribution
                    low_eff = sum(user_efficiency < 30)
                    high_eff = sum(user_efficiency >= 70)
                    print()
                    print(f"**Your Efficiency Distribution:**")
                    print(f"- **Low efficiency jobs** (< 30%): {low_eff} ({(low_eff/len(user_efficiency)*100):.1f}%)")
                    print(f"- **High efficiency jobs** (≥ 70%): {high_eff} ({(high_eff/len(user_efficiency)*100):.1f}%)")
                    
                    print()
                    print("**ROC Curve Interpretation:**")
                    print("- Each line shows how a user's jobs perform across efficiency thresholds")
                    print("- Your line (should be highlighted) shows your efficiency distribution")
                    print("- Lines higher and to the left indicate better efficiency performance")
                    print("- Use this to see how you rank among system users")
                
            else:
                print(f"**Error**: Not enough users for comparison (need ≥5, have {len(other_users)})")
        
    except Exception as e:
        print(f"**Error generating advanced ROC analysis**: {e}")
        print()
        print("Advanced ROC analysis could not be completed.")
        import traceback
        print(f"**Details**: {traceback.format_exc()}")
        
else:
    print("### Advanced ROC Analysis Not Available")
    print()
    if all_users_job_metrics is None:
        print("**Reason**: No job metrics data available")
    elif len(all_users_job_metrics) <= 100:
        print(f"**Reason**: Insufficient job metrics data (need >100, have {len(all_users_job_metrics)})")
    else:
        print(f"**Reason**: Insufficient user jobs (need >5, have {len(user_jobs_df)})")
    
    print()
    print("*Advanced ROC analysis requires sufficient job data with calculated efficiency metrics.*")
    print("*This analysis will become available as more GPU jobs are submitted to the system.*")
```

---

<div style="margin: 40px 0; padding: 20px; background-color: #e8f5e9; border-radius: 8px; border-left: 4px solid #4caf50;">
<h4 style="color: #2e7d32; margin-bottom: 10px;">🔍 Comparative Analysis</h4>
<p>The following section compares your performance metrics with other users in the system. This benchmarking helps identify areas where you're performing well and areas for improvement.</p>
</div>

---

## Comparison with All Users

### VRAM Efficiency Comparison

```{python}
#| echo: false
#| fig-cap: "Efficiency Comparison with All Users"
#| fig-width: 12
#| fig-height: 6

if len(comparison_stats_df) > 0:
    # Focus on efficiency metrics only
    efficiency_metrics = comparison_stats_df[comparison_stats_df['Category'].str.contains('efficiency|Efficiency', case=False, na=False)]
    
    if len(efficiency_metrics) > 0:
        fig, ax = plt.subplots(figsize=(12, 6))
        
        categories = efficiency_metrics['Category']
        your_values = efficiency_metrics['Your_Value']
        avg_values = efficiency_metrics['Average_Value']
        
        # Convert to percentage if values are between 0-1
        your_values_pct = [v * 100 if v <= 1 else v for v in your_values]
        avg_values_pct = [v * 100 if v <= 1 else v for v in avg_values]
        
        x = np.arange(len(categories))
        width = 0.35
        
        # Blue/Purple color scheme
        colors = ['#2E86AB', '#A23B72']
        
        bars1 = ax.bar(x - width/2, your_values_pct, width, label='Your Efficiency', 
                      color=colors[0], alpha=0.8, edgecolor='white', linewidth=1)
        bars2 = ax.bar(x + width/2, avg_values_pct, width, label='Average Efficiency', 
                      color=colors[1], alpha=0.8, edgecolor='white', linewidth=1)
        
        ax.set_xlabel('Efficiency Metrics', fontweight='bold')
        ax.set_ylabel('Efficiency (%)', fontweight='bold')
        ax.set_title('Your Efficiency vs. Average Users', fontweight='bold', fontsize=14)
        ax.set_xticks(x)
        
        # Set y-axis to 0-100% scale
        ax.set_ylim(0, 100)
        
        # Clean up category names
        cleaned_labels = []
        for cat in categories:
            clean_cat = cat.replace('Average ', '').replace('VRAM ', '').replace('efficiency', 'Efficiency')
            if len(clean_cat) > 25:
                clean_cat = clean_cat[:22] + '...'
            cleaned_labels.append(clean_cat)
        
        ax.set_xticklabels(cleaned_labels, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # Add value labels with percentage formatting
        for bar, value in zip(bars1, your_values_pct):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 2,
                   f'{value:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        for bar, value in zip(bars2, avg_values_pct):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 2,
                   f'{value:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    else:
        print("No efficiency metrics available for comparison.")
else:
    print("No comparison data available.")
```

### Key Performance Metrics

```{python}
#| echo: false
#| fig-cap: "Key Performance Metrics Comparison"
#| fig-width: 12
#| fig-height: 6

if len(comparison_stats_df) > 0:
    # Select only the most important comparison metrics (avoid scale issues)
    # Focus on efficiency, usage ratios, and normalized metrics
    important_metrics = comparison_stats_df[
        comparison_stats_df['Category'].str.contains(
            'efficiency|ratio|percentage|utilization|average.*memory.*per|time.*usage', 
            case=False, na=False
        )
    ]
    
    # Remove pure memory amounts (GiB) which cause scale issues
    important_metrics = important_metrics[
        ~important_metrics['Category'].str.contains('Total.*Memory|GPU.*Memory.*GiB|GB', case=False, na=False)
    ]
    
    if len(important_metrics) > 0:
        fig, ax = plt.subplots(figsize=(12, 6))
        
        categories = important_metrics['Category']
        your_values = important_metrics['Your_Value']
        avg_values = important_metrics['Average_Value']
        
        x = np.arange(len(categories))
        width = 0.35
        
        # Green color scheme for performance metrics
        colors = ['#4CAF50', '#8BC34A']
        
        bars1 = ax.bar(x - width/2, your_values, width, label='Your Performance', 
                      color=colors[0], alpha=0.8, edgecolor='white', linewidth=1)
        bars2 = ax.bar(x + width/2, avg_values, width, label='Average Performance', 
                      color=colors[1], alpha=0.8, edgecolor='white', linewidth=1)
        
        ax.set_xlabel('Performance Metrics', fontweight='bold')
        ax.set_ylabel('Percentage (%)', fontweight='bold')
        ax.set_title('Key Performance Indicators Comparison', fontweight='bold', fontsize=14)
        ax.set_xticks(x)
        
        # Set y-axis limits for percentage scale (0-100% with some padding above)
        max_val = max(max(your_values) if len(your_values) > 0 else 0, 
                     max(avg_values) if len(avg_values) > 0 else 0)
        y_limit = min(max(max_val * 1.1, 105), 110)  # At least 105%, max 110%
        ax.set_ylim(0, y_limit)
        
        # Clean up category names
        cleaned_labels = []
        for cat in categories:
            clean_cat = cat.replace('Average ', '').replace('Total ', '')
            if len(clean_cat) > 25:
                clean_cat = clean_cat[:22] + '...'
            cleaned_labels.append(clean_cat)
        
        ax.set_xticklabels(cleaned_labels, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3, axis='y')
        
        # Add value labels with percentage formatting
        for bar, value in zip(bars1, your_values):
            height = bar.get_height()
            # Format as percentage since these are efficiency metrics
            label = f'{value:.1f}%'
            ax.text(bar.get_x() + bar.get_width()/2., height + y_limit * 0.02,
                   label, ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        for bar, value in zip(bars2, avg_values):
            height = bar.get_height()
            # Format as percentage since these are efficiency metrics
            label = f'{value:.1f}%'
            ax.text(bar.get_x() + bar.get_width()/2., height + y_limit * 0.02,
                   label, ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    else:
        print("No key performance metrics available for comparison.")
else:
    print("No comparison data available.")
```

---

</details>

---

<details>
<summary><h2 style="display: inline-block; margin: 0;">📈 Analysis over Time</h2></summary>

<div style="margin: 35px 0; padding: 18px; background-color: #f0f8ff; border-radius: 8px; border-left: 4px solid #2196f3;">
<p>Understanding how your GPU usage patterns change over time helps identify trends, seasonal variations, and improvement opportunities. The following visualizations show your performance evolution.</p>
</div>

<details>
<summary><h4>📈 Job Count Over Time</h4></summary>

```{python}
#| echo: false
#| fig-cap: "Job Count Over Time"
#| fig-width: 12
#| fig-height: 6

if len(time_series_data_df) > 0:
    # Use the time series data for job count visualization
    if 'JobCount' in time_series_data_df.columns:
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # Get the appropriate time column
        x_col = 'TimeGroup_Datetime' if 'TimeGroup_Datetime' in time_series_data_df.columns else 'TimeGroup_Str'
        
        # Convert to datetime if needed
        if x_col == 'TimeGroup_Datetime' and time_series_data_df[x_col].dtype == 'object':
            time_series_data_df[x_col] = pd.to_datetime(time_series_data_df[x_col])
        
        # Create a clean line plot with markers
        ax.plot(time_series_data_df[x_col], time_series_data_df['JobCount'], 
               marker='o', linewidth=2.5, markersize=8, color='#2E8B57', 
               markerfacecolor='#90EE90', markeredgecolor='#2E8B57', markeredgewidth=2)
        
        # Fill area under the curve for better visual appeal
        ax.fill_between(time_series_data_df[x_col], time_series_data_df['JobCount'], 
                       alpha=0.3, color='#90EE90')
        
        # Add horizontal line for average
        avg_jobs = time_series_data_df['JobCount'].mean()
        ax.axhline(y=avg_jobs, color='red', linestyle='--', alpha=0.7, 
                  label=f'Average: {avg_jobs:.1f} jobs')
        
        ax.set_xlabel('Time Period', fontsize=12)
        ax.set_ylabel('Number of Jobs', fontsize=12)
        ax.set_title('Job Submission Activity Over Time', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Improve x-axis formatting
        if x_col == 'TimeGroup_Datetime':
            plt.xticks(rotation=45)
        else:
            # For string dates, show fewer labels to avoid crowding
            n_ticks = min(8, len(time_series_data_df))
            tick_indices = np.linspace(0, len(time_series_data_df)-1, n_ticks, dtype=int)
            ax.set_xticks([time_series_data_df[x_col].iloc[i] for i in tick_indices])
            plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.show()
    else:
        print("Job count data not available in time series.")
else:
    print("No time series data available for job count visualization.")
```

</details>

<details>
<summary><h4>📊 VRAM Efficiency Over Time (Monthly)</h4></summary>

```{python}
#| echo: false
#| fig-cap: "VRAM Efficiency Over Time - Monthly"
#| fig-width: 12
#| fig-height: 8

import matplotlib.pyplot as plt
import pandas as pd

if len(user_jobs) > 0 and 'StartTime' in user_jobs.columns:
    try:
        from src.analysis.frequency_analysis import FrequencyAnalysis
        from src.visualization.time_series import TimeSeriesVisualizer
        from src.config.enum_constants import TimeUnitEnum
        
        # Use frequency analysis to prepare monthly time series data
        frequency_analyzer = FrequencyAnalysis(user_jobs)
        
        # Prepare monthly time series data for the user
        monthly_data = frequency_analyzer.prepare_time_series_data(
            users=[user_id],
            metric="alloc_vram_efficiency" if "alloc_vram_efficiency" in user_jobs.columns else "used_vram_gib",
            time_unit=TimeUnitEnum.MONTHS,
            remove_zero_values=False
        )
        
        if len(monthly_data) > 0:
            # Map columns for TimeSeriesVisualizer
            monthly_data['Efficiency'] = monthly_data['Metric']
            monthly_data['GPU_Hours'] = monthly_data['GPUHours']
            
            # Create the time series visualizer
            ts_visualizer = TimeSeriesVisualizer(monthly_data)
            
            # Plot VRAM efficiency over time
            ts_visualizer.plot_vram_efficiency(
                users=[user_id],
                annotation_style="none",
                show_secondary_y=False
            )
        else:
            print("No monthly time series data available for this user.")
        
    except Exception as e:
        print(f"Error using FrequencyAnalysis for monthly time series: {e}")
        # Fallback to basic time series plot
        if 'StartTime' in user_jobs.columns:
            user_jobs_sorted = user_jobs.sort_values('StartTime').copy()
            
            # Group by month for fallback
            user_jobs_sorted['Month'] = pd.to_datetime(user_jobs_sorted['StartTime']).dt.to_period('M')
            monthly_avg = user_jobs_sorted.groupby('Month').agg({
                'alloc_vram_efficiency': 'mean' if 'alloc_vram_efficiency' in user_jobs_sorted.columns else lambda x: 0
            }).reset_index()
            
            if len(monthly_avg) > 0:
                plt.figure(figsize=(12, 6))
                plt.plot(monthly_avg['Month'].astype(str), monthly_avg['alloc_vram_efficiency'], 
                        marker='o', linewidth=2, markersize=6)
                plt.xlabel('Month')
                plt.ylabel('VRAM Efficiency')
                plt.title('VRAM Efficiency Over Time (Monthly Average)')
                plt.xticks(rotation=45)
                plt.grid(True, alpha=0.3)
                plt.tight_layout()
                plt.show()
            else:
                print("No time-based data available for efficiency analysis.")
else:
    print("No job data with timestamps available for time series analysis.")
```

</details>

<details>
<summary><h4>🎯 Individual Job Performance (Dot Plot)</h4></summary>

```{python}
#| echo: false
#| fig-cap: "Individual Job Performance Over Time"
#| fig-width: 12
#| fig-height: 8

# Always show the dot plot for individual job performance
if len(user_jobs) > 0 and 'StartTime' in user_jobs.columns:
    try:
        from src.visualization.time_series import TimeSeriesVisualizer
        
        # Create time series visualizer with user job data
        ts_visualizer = TimeSeriesVisualizer(user_jobs)
        
        # Plot individual job performance as dots
        ts_visualizer.plot_vram_efficiency_per_job_dot(
            users=[user_id],
            efficiency_metric='alloc_vram_efficiency' if 'alloc_vram_efficiency' in user_jobs.columns else 'used_vram_gib',
            vram_metric='vram_hours' if 'vram_hours' in user_jobs.columns else 'job_hours',
            remove_zero_values=True
        )
        
    except Exception as e:
        print(f"Error creating dot plot: {e}")
        # Fallback scatter plot
        if 'alloc_vram_efficiency' in user_jobs.columns:
            plt.figure(figsize=(12, 6))
            plt.scatter(user_jobs['StartTime'], user_jobs['alloc_vram_efficiency'], 
                       alpha=0.6, s=50)
            plt.xlabel('Date')
            plt.ylabel('VRAM Efficiency')
            plt.title('Individual Job VRAM Efficiency Over Time')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.show()

else:
    print("No job data with timestamps available for dot plot.")
```

</details>

</details>

---

## Summary Table

```{python}
#| echo: false

# Display the summary statistics table at the bottom
if len(summary_stats_df) > 0:
    from IPython.display import display, HTML
    
    # Create a comprehensive summary table
    table_html = summary_stats_df.to_html(
        index=False,
        escape=False,
        classes='table table-striped table-hover',
        table_id='bottom-summary-table',
        border=0
    )
    
    # Add custom CSS styling
    styled_table = f"""
    <style>
    #bottom-summary-table {{
        width: 100%;
        margin: 20px 0;
        border-collapse: collapse;
        font-family: Arial, sans-serif;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-radius: 8px;
        overflow: hidden;
    }}
    #bottom-summary-table th {{
        background-color: #2E8B57;
        color: white;
        font-weight: bold;
        padding: 12px 15px;
        text-align: left;
        border: none;
    }}
    #bottom-summary-table td {{
        padding: 12px 15px;
        border-bottom: 1px solid #ddd;
        background-color: #f9f9f9;
    }}
    #bottom-summary-table tr:nth-child(even) td {{
        background-color: #f2f2f2;
    }}
    #bottom-summary-table tr:hover td {{
        background-color: #e8f5e8;
    }}
    </style>
    <h3>📋 Complete Performance Summary</h3>
    {table_html}
    """
    
    display(HTML(styled_table))
else:
    print("📋 **Complete Performance Summary**")
    print("No summary statistics available.")
```

---

## All Recommendations

```{python}
#| echo: false
#| output: asis

if recommendations and len(recommendations) > 0:
    print("Based on your complete GPU usage analysis, here are all recommendations to improve efficiency:\n")
    for i, rec in enumerate(recommendations, 1):
        print(f"{i}. {rec}\n")
else:
    print("No specific recommendations provided. Generally, focus on optimizing GPU memory usage and time allocation for better efficiency.")
```

---

## Additional Resources

For more information on optimizing your GPU usage, please refer to these resources:

1. [Unity HPC Documentation](https://docs.unity.rc.umass.edu/)
2. [GPU Programming Best Practices](https://docs.unity.rc.umass.edu/documentation/tools/gpus/)
3. [Contact Unity on Slack](https://docs.unity.rc.umass.edu/contact/community/)

---

*Report generated on `{python} datetime.now().strftime("%Y-%m-%d %H:%M:%S")`*
