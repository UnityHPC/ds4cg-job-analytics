{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Analysis of GPU Jobs that Requested and Used VRAM](#toc0_)\n",
    "This notebook generates the analysis for jobs that requested some VRAM and run on partitions that their type is GPU and some GPU VRAM is used. It looks at these jobs, corresponding users, and PI groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Analysis of GPU Jobs that Requested and Used VRAM](#toc1_)    \n",
    "  - [Setup](#toc1_1_)    \n",
    "  - [Data Digestion and Preprocessing](#toc1_2_)    \n",
    "  - [Narrowing Dataset Down to the Relevant Partition](#toc1_3_)    \n",
    "  - [Generate Baseline Metrics](#toc1_4_)    \n",
    "  - [Job-Level Analysis](#toc1_5_)    \n",
    "      - [Find most inefficient jobs with no VRAM constraints based on `requested_vram_efficiency_score`](#toc1_5_1_1_)    \n",
    "    - [Generate all hoarding analysis metrics for jobs:](#toc1_5_2_)    \n",
    "      - [Find most inefficient jobs hoarding node RAM based on `ram_hoarding_fraction_diff`](#toc1_5_2_1_)    \n",
    "      - [Find most inefficient jobs hoarding CPU cores based on `core_hoarding_fraction_diff`](#toc1_5_2_2_)    \n",
    "  - [User-Level Analysis](#toc1_6_)    \n",
    "    - [Find Inefficient Users based on `requested_vram_efficiency_score`](#toc1_6_1_)    \n",
    "    - [Generate all hoarding analysis metrics for users:](#toc1_6_2_)    \n",
    "      - [Find most inefficient users hoarding node RAM based on `expected_value_ram_hoarding_fraction_diff`](#toc1_6_2_1_)    \n",
    "      - [Find most inefficient users hoarding CPU cores based on `expected_value_core_hoarding_fraction_diff`](#toc1_6_2_2_)    \n",
    "  - [PI Group Analysis](#toc1_7_)    \n",
    "      - [Find Inefficient PIs based on `avg_requested_vram_efficiency_score`](#toc1_7_1_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Jupyter server should be run at the notebook directory, so the output of the following cell would be the project root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path.cwd().resolve().parent.parent\n",
    "print(f\"Project root: {project_root.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload modules before executing code (set this up BEFORE imports)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Add project root to sys.path for module imports\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.analysis import ResourceHoarding\n",
    "from src.analysis import efficiency_analysis as ea\n",
    "from src.visualization import (\n",
    "    JobsWithMetricsVisualizer,\n",
    "    UsersWithMetricsVisualizer,\n",
    "    PIGroupsWithMetricsVisualizer,\n",
    ")\n",
    "from src.config.enum_constants import ResourceHoardingDataFrameNameEnum\n",
    "from src.config.paths import (\n",
    "    JOBS_VISUALIZATION_DATA_DIR,\n",
    "    USERS_VISUALIZATION_DATA_DIR,\n",
    "    PI_GROUPS_VISUALIZATION_DATA_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Data Digestion and Preprocessing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jobs DataFrame from DuckDB\n",
    "preprocessed_jobs_df = ea.load_preprocessed_jobs_dataframe_from_duckdb(\n",
    "    db_path=Path(project_root) / \"data/slurm_data.db\",\n",
    "    table_name=\"Jobs\",\n",
    "    anonymize=True,\n",
    ")\n",
    "display(preprocessed_jobs_df.head(10))\n",
    "print(preprocessed_jobs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Narrowing Dataset Down to the Relevant Partition](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = ResourceHoarding(jobs_df=preprocessed_jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_jobs = analyzer.filter_jobs_for_analysis(\n",
    "    gpu_mem_usage_filter={\"min\": 0, \"inclusive\": False}, requested_vram_filter={\"min\": 0, \"inclusive\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Generate Baseline Metrics](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = analyzer.calculate_all_efficiency_metrics(filtered_jobs)\n",
    "\n",
    "jobs_with_metrics = metrics_dict[\"jobs_with_efficiency_metrics\"]\n",
    "users_with_metrics = metrics_dict[\"users_with_efficiency_metrics\"]\n",
    "pi_accounts_with_metrics = metrics_dict[\"pi_accounts_with_efficiency_metrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Job-Level Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Display the DataFrame\n",
    "display(jobs_with_metrics.head(5))\n",
    "# To revert to default settings (optional)\n",
    "pd.reset_option(\"display.max_columns\")\n",
    "\n",
    "print(f\"Jobs found: {len(jobs_with_metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_1_1_'></a>[Find most inefficient jobs with no VRAM constraints based on `requested_vram_efficiency_score`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_jobs_vram_hours = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.JOBS,\n",
    "    sorting_key=\"requested_vram_efficiency_score\",\n",
    "    ascending=True,  # Sort by requested_vram_efficiency_score in ascending order\n",
    "    filter_criteria={\n",
    "        \"alloc_vram_efficiency_score\": {\"max\": -10, \"inclusive\": True},  # score threshold\n",
    "    },\n",
    ")\n",
    "# Plot top inefficient jobs by requested VRAM efficiency score, with VRAM-hours as labels\n",
    "jobs_with_metrics_visualizer = JobsWithMetricsVisualizer(inefficient_jobs_vram_hours.head(10))\n",
    "jobs_with_metrics_visualizer.visualize(\n",
    "    output_dir_path=JOBS_VISUALIZATION_DATA_DIR,\n",
    "    column=\"requested_vram_efficiency_score\",\n",
    "    bar_label_columns=[\"vram_hours\", \"allocated_vram\"],\n",
    "    figsize=(10, 6),\n",
    "    anonymize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Generate all hoarding analysis metrics for jobs:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_hoarding_jobs = analyzer.calculate_node_resource_hoarding_for_jobs(filtered_jobs)\n",
    "\n",
    "# Set option to display all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# Display the DataFrame\n",
    "display(memory_hoarding_jobs.head(5))\n",
    "# To revert to default settings (optional)\n",
    "pd.reset_option(\"display.max_columns\")\n",
    "\n",
    "print(f\"Jobs found: {len(memory_hoarding_jobs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_2_1_'></a>[Find most inefficient jobs hoarding node RAM based on `ram_hoarding_fraction_diff`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_jobs_hoarding_ram = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.JOBS_WITH_RESOURCE_HOARDING_METRICS,\n",
    "    sorting_key=\"ram_hoarding_fraction_diff\",\n",
    "    ascending=False,  # Sort in descending order\n",
    "    filter_criteria={\"ram_hoarding_fraction_diff\": {\"min\": 0, \"inclusive\": True}},\n",
    ")\n",
    "# Plot top inefficient jobs by RAM hoarding fraction, with RAM hoarding fraction as labels\n",
    "jobs_with_metrics_visualizer = JobsWithMetricsVisualizer(inefficient_jobs_hoarding_ram.head(10))\n",
    "jobs_with_metrics_visualizer.visualize(\n",
    "    column=\"ram_hoarding_fraction_diff\",\n",
    "    bar_label_columns=[\"cpu_mem_efficiency\", \"alloc_vram_efficiency\"],\n",
    "    figsize=(10, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_2_2_'></a>[Find most inefficient jobs hoarding CPU cores based on `core_hoarding_fraction_diff`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_jobs_hoarding_cpu_cores = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.JOBS_WITH_RESOURCE_HOARDING_METRICS,\n",
    "    sorting_key=\"core_hoarding_fraction_diff\",\n",
    "    ascending=False,  # Sort in descending order\n",
    "    filter_criteria={\"core_hoarding_fraction_diff\": {\"min\": 0, \"inclusive\": True}},\n",
    ")\n",
    "\n",
    "# Plot top inefficient jobs by CPU core hoarding fraction, with CPU core hoarding fraction as labels\n",
    "jobs_with_metrics_visualizer = JobsWithMetricsVisualizer(inefficient_jobs_hoarding_cpu_cores.head(10))\n",
    "jobs_with_metrics_visualizer.visualize(\n",
    "    column=\"core_hoarding_fraction_diff\",\n",
    "    bar_label_columns=[\"ram_hoarding_fraction_diff\", \"alloc_vram_efficiency\"],\n",
    "    figsize=(10, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[User-Level Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Find Inefficient Users based on `requested_vram_efficiency_score`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_users_avg_req_vram_eff_score = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.USERS,\n",
    "    sorting_key=\"avg_requested_vram_efficiency_score\",\n",
    "    ascending=True,  # Sort by avg_requested_vram_efficiency_score in ascending order\n",
    "    filter_criteria={\n",
    "        \"avg_requested_vram_efficiency_score\": {\"max\": -10, \"inclusive\": True},  # score threshold\n",
    "        \"job_count\": {\"min\": 5, \"inclusive\": True},  # minimum job count threshold\n",
    "    },\n",
    ")\n",
    "# Plot top inefficient users by Avg Requested VRAM Efficiency Score, with avg_requested_vram_efficiency_score as labels\n",
    "users_with_metrics_visualizer = UsersWithMetricsVisualizer(inefficient_users_avg_req_vram_eff_score.head(10))\n",
    "users_with_metrics_visualizer.visualize(\n",
    "    column=\"avg_requested_vram_efficiency_score\",\n",
    "    bar_label_columns=[\"vram_hours\", \"job_count\"],\n",
    "    figsize=(10, 6),\n",
    "    anonymize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_with_metrics_visualizer = UsersWithMetricsVisualizer(inefficient_users_avg_req_vram_eff_score)\n",
    "users_with_metrics_visualizer.visualize_metric_distribution(\n",
    "    output_dir_path=USERS_VISUALIZATION_DATA_DIR, column=\"avg_requested_vram_efficiency_score\", figsize=(8, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_users_ev_req_vram_eff = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.USERS,\n",
    "    sorting_key=\"expected_value_requested_vram_efficiency\",\n",
    "    ascending=True,  # Sort by expected_value_requested_vram_efficiency in ascending order\n",
    "    filter_criteria={\n",
    "        \"job_count\": {\"min\": 5, \"inclusive\": True},  # minimum job count threshold\n",
    "    },\n",
    ")\n",
    "users_with_metrics_ev_visualizer = UsersWithMetricsVisualizer(inefficient_users_ev_req_vram_eff)\n",
    "users_with_metrics_ev_visualizer.visualize_metric_distribution(\n",
    "    output_dir_path=USERS_VISUALIZATION_DATA_DIR, column=\"expected_value_requested_vram_efficiency\", figsize=(8, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_2_'></a>[Generate all hoarding analysis metrics for users:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_hoarding_users = analyzer.calculate_node_resource_hoarding_for_users(filtered_jobs)\n",
    "display(memory_hoarding_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### <a id='toc1_6_2_1_'></a>[Find most inefficient users hoarding node RAM based on `expected_value_ram_hoarding_fraction_diff`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_users_hoarding_ram = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.USERS_WITH_RESOURCE_HOARDING_METRICS,\n",
    "    sorting_key=\"expected_value_ram_hoarding_fraction_diff\",\n",
    "    ascending=False,  # Sort in descending order\n",
    "    filter_criteria={\"expected_value_ram_hoarding_fraction_diff\": {\"min\": 0, \"inclusive\": True}},\n",
    ")\n",
    "# Plot top inefficient users by RAM hoarding fraction, with RAM hoarding fraction as labels\n",
    "users_with_metrics_visualizer = UsersWithMetricsVisualizer(inefficient_users_hoarding_ram.head(10))\n",
    "users_with_metrics_visualizer.visualize(\n",
    "    column=\"expected_value_ram_hoarding_fraction_diff\",\n",
    "    bar_label_columns=[\n",
    "        \"expected_value_alloc_vram_efficiency\",\n",
    "    ],\n",
    "    figsize=(10, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### <a id='toc1_6_2_2_'></a>[Find most inefficient users hoarding CPU cores based on `expected_value_core_hoarding_fraction_diff`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_users_hoarding_cpu_cores = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.USERS_WITH_RESOURCE_HOARDING_METRICS,\n",
    "    sorting_key=\"expected_value_core_hoarding_fraction_diff\",\n",
    "    ascending=False,  # Sort in descending order\n",
    "    filter_criteria={\"expected_value_core_hoarding_fraction_diff\": {\"min\": 0, \"inclusive\": True}},\n",
    ")\n",
    "# Plot top inefficient users by CPU core hoarding fraction, with CPU core hoarding fraction as labels\n",
    "users_with_metrics_visualizer = UsersWithMetricsVisualizer(inefficient_users_hoarding_cpu_cores.head(10))\n",
    "users_with_metrics_visualizer.visualize(\n",
    "    column=\"expected_value_core_hoarding_fraction_diff\",\n",
    "    bar_label_columns=[\n",
    "        \"expected_value_alloc_vram_efficiency\",\n",
    "    ],\n",
    "    figsize=(10, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[PI Group Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_accounts_with_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### <a id='toc1_7_1_1_'></a>[Find Inefficient PIs based on `avg_requested_vram_efficiency_score`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_pis_avg_req_vram_eff_score = analyzer.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ResourceHoardingDataFrameNameEnum.PI_GROUPS,\n",
    "    sorting_key=\"avg_requested_vram_efficiency_score\",\n",
    "    ascending=True,  # more negative first\n",
    "    filter_criteria={\n",
    "        \"avg_requested_vram_efficiency_score\": {\"max\": -10, \"inclusive\": True},\n",
    "        \"job_count\": {\"min\": 5, \"inclusive\": True},  # Minimum number of jobs to consider a PI account\n",
    "    },\n",
    ")\n",
    "pis_with_metrics_visualizer = PIGroupsWithMetricsVisualizer(inefficient_pis_avg_req_vram_eff_score.head(10))\n",
    "pis_with_metrics_visualizer.visualize(\n",
    "    output_dir_path=PI_GROUPS_VISUALIZATION_DATA_DIR,\n",
    "    column=\"avg_requested_vram_efficiency_score\",\n",
    "    bar_label_columns=[\"pi_acc_job_hours\", \"pi_acc_vram_hours\"],\n",
    "    figsize=(10, 6),\n",
    "    anonymize=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
