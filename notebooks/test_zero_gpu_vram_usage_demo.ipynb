{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99c534f",
   "metadata": {},
   "source": [
    "# Test and Demonstrate zero_gpu_vram_usage Analysis\n",
    "\n",
    "This notebook tests and demonstrates the main functions in `src/analysis/zero_gpu_vram_usage.py` for analyzing hybrid workload efficiency and CPU-GPU balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474cfe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd2d9f",
   "metadata": {},
   "source": [
    "Jupyter server should be run at the notebook directory, so the output of the following cell would be the project root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = str(Path.cwd().resolve().parent)\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to sys.path for module imports\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.analysis import zero_gpu_vram_usage\n",
    "\n",
    "# Automatically reload modules before executing code\n",
    "# This is useful for development to see changes without restarting the kernel.\n",
    "%load_ext autoreload\n",
    "# Reload all modules imported with %aimport every time before executing the Python code typed.\n",
    "%autoreload 1\n",
    "%aimport src.analysis.zero_gpu_vram_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9359836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jobs DataFrame from DuckDB\n",
    "\n",
    "df = zero_gpu_vram_usage.load_jobs_dataframe_from_duckdb(db_path='../data/slurm_data.db')\n",
    "display(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6902e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analyze_hybrid_workload_efficiency with modular filters\n",
    "# Example: Only jobs with 0GB requested, at least 1 GPU, and at least 600s duration\n",
    "# You can change the arguments to filter for different criteria\n",
    "\n",
    "df_hybrid = zero_gpu_vram_usage.analyze_hybrid_workload_efficiency(\n",
    "    df,\n",
    "    requested_vram_filter=0,  # or a function, e.g., lambda x: x <= 2\n",
    "    allocated_vram_greater_than=0,\n",
    "    gpu_mem_usage_min = None,\n",
    "    gpu_mem_usage_max = None,\n",
    "    gpu_mem_usage_exact= 0,\n",
    "    gpus_min=1,\n",
    "    elapsed_seconds_min=0,  # all jobs\n",
    ")\n",
    "\n",
    "# Set option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display the DataFrame\n",
    "display(df_hybrid.head())\n",
    "# To revert to default settings (optional)\n",
    "pd.reset_option('display.max_columns')\n",
    "print(f\"Hybrid jobs found: {len(df_hybrid)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9160ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluate_cpu_gpu_balance\n",
    "analysis_results = zero_gpu_vram_usage.evaluate_cpu_gpu_balance(df_hybrid)\n",
    "\n",
    "# Display key summary statistics\n",
    "print(\"Total jobs:\", analysis_results[\"total_jobs\"])\n",
    "print(\"Total GPU hours:\", analysis_results[\"total_gpu_hours\"])\n",
    "print(\"Average VRAM efficiency:\", f\"{analysis_results['avg_efficiency']:.2%}\")\n",
    "print(\"Median VRAM efficiency:\", f\"{analysis_results['median_efficiency']:.2%}\")\n",
    "\n",
    "# Show recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in analysis_results[\"recommendations\"]:\n",
    "    print(\"-\", rec)\n",
    "# Display efficiency patterns table\n",
    "analysis_results[\"efficiency_patterns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot VRAM efficiency distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_hybrid[\"vram_efficiency\"].dropna(), bins=30, kde=True)\n",
    "plt.xlabel(\"VRAM Efficiency\")\n",
    "plt.ylabel(\"Number of Jobs\")\n",
    "plt.title(\"Distribution of VRAM Efficiency for Hybrid Jobs\")\n",
    "plt.xlim(0, 1.0)\n",
    "plt.show()\n",
    "\n",
    "# print(analysis_results['top_inefficient_users'].head(5))\n",
    "\n",
    "# Plot top inefficient users by GPU hours\n",
    "if \"top_inefficient_users\" in analysis_results:\n",
    "    top_users = analysis_results[\"top_inefficient_users\"].head(10)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(y=top_users.index, x=top_users[\"GPU_Hours\"], orient=\"h\")\n",
    "    plt.xlabel(\"GPU Hours\")\n",
    "    plt.ylabel(\"User\")\n",
    "    plt.title(\"Top 10 Inefficient Users by GPU Hours (Hybrid Jobs)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54827579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter jobs where 0GB VRAM was requested but a GPU was allocated (modular function)\n",
    "# You can change requested_vram and gpus_min as needed\n",
    "zero_vram_jobs = zero_gpu_vram_usage.filter_zero_vram_requested_with_gpu_allocated(df, requested_vram=0, gpus_min=1)\n",
    "display(zero_vram_jobs.head(10))\n",
    "print(f\"Found {len(zero_vram_jobs)} jobs where 0GB VRAM was requested but a GPU was allocated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Plot statistics for jobs where 0GB VRAM was requested but a GPU was allocated\n",
    "if not zero_vram_jobs.empty:\n",
    "    # Plot distribution of GPU memory usage\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(zero_vram_jobs[\"GPUMemUsage\"].dropna(), bins=30, kde=True)\n",
    "    plt.xlabel(\"GPU Memory Usage (bytes)\")\n",
    "    plt.ylabel(\"Number of Jobs\")\n",
    "    plt.title(\"Distribution of GPU Memory Usage (0GB VRAM Requested)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Plot distribution of job durations (Elapsed_seconds)\n",
    "    if \"Elapsed_seconds\" in zero_vram_jobs.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        # Line plot of histogram (number of jobs vs. duration in hours)\n",
    "        counts, bins = np.histogram(zero_vram_jobs[\"Elapsed_seconds\"].dropna() / 3600, bins=30)\n",
    "        bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "        plt.plot(bin_centers, counts, marker='o', linestyle='-')\n",
    "        plt.xlabel(\"Job Duration (hours)\")\n",
    "        plt.ylabel(\"Number of Jobs\")\n",
    "        plt.title(\"Distribution of Job Durations (0GB VRAM Requested)\")\n",
    "        plt.show()\n",
    "\n",
    "    # Plot number of jobs by user\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    user_counts = zero_vram_jobs[\"User\"].value_counts().head(20)\n",
    "    sns.barplot(x=user_counts.values, y=user_counts.index, orient=\"h\")\n",
    "    plt.xlabel(\"Number of Jobs\")\n",
    "    plt.ylabel(\"User\")\n",
    "    plt.title(\"Top 20 Users: Jobs with 0GB VRAM Requested but GPU Allocated\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No jobs found where 0GB VRAM was requested but a GPU was allocated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1448a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duckdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
