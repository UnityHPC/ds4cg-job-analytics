{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Analyze High Memory Usage Across Jobs Resulting in Hoarding of Resources:](#toc1_1_)    \n",
    "      - [Find most inefficient jobs hoarding node RAM based on `ram_hoarding_fraction_diff`](#toc1_1_1_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Jupyter server should be run at the notebook directory, so the output of the following cell would be the project root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = str(Path.cwd().resolve().parent)\n",
    "print(f\"Project root: {project_root}\")\n",
    "os.environ[\"OUTPUT_MODE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to sys.path for module imports\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.analysis import ResourceHoarding as ResourceHoarding\n",
    "from src.analysis import efficiency_analysis as ea\n",
    "from src.visualization import JobsWithMetricsVisualizer\n",
    "\n",
    "# Automatically reload modules before executing code\n",
    "# This is useful for development to see changes without restarting the kernel.\n",
    "%load_ext autoreload\n",
    "# Reload all modules imported with %aimport every time before executing the Python code typed.\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the jobs DataFrame from DuckDB\n",
    "preprocessed_jobs_df = ea.load_preprocessed_jobs_dataframe_from_duckdb(\n",
    "    db_path='../data/slurm_data.db',\n",
    "    table_name='Jobs',\n",
    "    )\n",
    "display(preprocessed_jobs_df.head(10))\n",
    "print(preprocessed_jobs_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Analyze High Memory Usage Across Jobs Resulting in Hoarding of Resources:](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoarding_analysis = ResourceHoarding(jobs_df=preprocessed_jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_jobs = hoarding_analysis.filter_jobs_for_analysis()\n",
    "filtered_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Generate all hoarding analysis metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_hoarding_jobs = hoarding_analysis.calculate_memory_hoarding(filtered_jobs)\n",
    "\n",
    "# Set option to display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Display the DataFrame\n",
    "display(memory_hoarding_jobs.head(10))\n",
    "# To revert to default settings (optional)\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "print(f\"Jobs found: {len(memory_hoarding_jobs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### <a id='toc1_1_1_1_'></a>[Find most inefficient jobs hoarding node RAM based on `ram_hoarding_fraction_diff`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "inefficient_jobs_hoarding_ram = hoarding_analysis.sort_and_filter_records_with_metrics(\n",
    "    metrics_df_name_enum=ea.MetricsDataFrameNameEnum.JOBS,\n",
    "    sorting_key=\"ram_hoarding_fraction_diff\",\n",
    "    ascending=False,  # Sort in descending order\n",
    "    filter_criteria={\n",
    "        \"ram_hoarding_fraction_diff\": {\"min\": 0, \"inclusive\": True}\n",
    "    },\n",
    ")\n",
    "# Display top inefficient users by RAM hoarding fraction\n",
    "print(\"\\nTop inefficient Jobs by RAM hoarding fraction:\")\n",
    "display(inefficient_jobs_hoarding_ram.head(10))\n",
    "\n",
    "# Plot top inefficient jobs by RAM hoarding fraction, with RAM hoarding fraction as labels\n",
    "jobs_with_metrics_visualizer = JobsWithMetricsVisualizer(inefficient_jobs_hoarding_ram.head(20))\n",
    "jobs_with_metrics_visualizer.visualize(\n",
    "    column=\"ram_hoarding_fraction_diff\",\n",
    "    bar_label_columns=[\"ram_hoarding_fraction_diff\", \"cpu_mem_efficiency\", \"alloc_vram_efficiency\"],\n",
    "    figsize=(12, 12),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
