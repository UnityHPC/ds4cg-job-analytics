{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to sys.path for module imports\n",
    "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "from src.database.database_connection import DatabaseConnection\n",
    "\n",
    "# Connect to the database\n",
    "db = DatabaseConnection(db_url=\"../slurm_data.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bafb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query jobs with GPUs\n",
    "gpu_df = db.connection.query(\"SELECT * FROM Jobs WHERE GPUs > 0\").to_df()\n",
    "\n",
    "# Display the data\n",
    "print(gpu_df.head())\n",
    "print(f\"Number of jobs with GPUs: {len(gpu_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063448c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = str(Path.cwd().resolve().parent)\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add project root to sys.path for module imports\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "\n",
    "# Automatically reload modules before executing code\n",
    "# This is useful for development to see changes without restarting the kernel.\n",
    "%load_ext autoreload\n",
    "# Reload all modules imported with %aimport every time before executing the Python code typed.\n",
    "%autoreload 1\n",
    "%aimport src.analysis.vram_usage, src.preprocess.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import analysis and preprocess functions\n",
    "from src.analysis.vram_usage import EfficiencyAnalysis\n",
    "from src.preprocess.preprocess import preprocess_data\n",
    "\n",
    "new_df = preprocess_data(\n",
    "    gpu_df, min_elapsed_seconds=0, include_failed_cancelled_jobs=False, include_cpu_only_jobs=True\n",
    ")\n",
    "\n",
    "# Initialize the EfficiencyAnalysis class\n",
    "efficiency_analyzer = EfficiencyAnalysis(df=new_df, table_name=\"Jobs\")\n",
    "\n",
    "# Load and preprocess data\n",
    "df_multi_gpu = efficiency_analyzer.jobs_df\n",
    "\n",
    "# Display the loaded data\n",
    "print(df_multi_gpu.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the efficiency metrics calculation\n",
    "import numpy as np\n",
    "\n",
    "new_df = efficiency_analyzer.filter_jobs_for_analysis(\n",
    "    gpu_count_filter=1, vram_constraint_filter=None, gpu_mem_usage_filter={\"min\": 0, \"max\": np.inf, \"inclusive\": False}\n",
    ")\n",
    "efficiency_metrics = efficiency_analyzer.calculate_job_efficiency_metrics(new_df)\n",
    "\n",
    "# Display the calculated efficiency metrics\n",
    "print(efficiency_metrics.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate CPU-GPU usage\n",
    "analysis_results = efficiency_analyzer.evaluate_cpu_gpu_usage(\n",
    "    hours_percentage_threshold=25, vram_efficiency_threshold=0.3\n",
    ")\n",
    "\n",
    "# Display key summary statistics\n",
    "print(\"Total jobs:\", analysis_results[\"total_jobs\"])\n",
    "print(\"Total GPU hours:\", f\"{analysis_results['total_gpu_hours']:.2f}\")\n",
    "print(\"Average VRAM efficiency:\", f\"{analysis_results['avg_efficiency']:.2%}\")\n",
    "print(\"Median VRAM efficiency:\", f\"{analysis_results['median_efficiency']:.2%}\")\n",
    "\n",
    "# Show recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for rec in analysis_results[\"report\"]:\n",
    "    print(\"-\", rec)\n",
    "\n",
    "# Display efficiency patterns table\n",
    "display(analysis_results[\"efficiency_patterns\"])\n",
    "\n",
    "# Visualize the analysis results\n",
    "cpu_gpu_balance = analysis_results.get(\"cpu_gpu_balance\", None)\n",
    "if cpu_gpu_balance is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # cpu_gpu_balance['Job_Count'].plot(kind='bar', color='green')\n",
    "    plt.xlabel(\"Workload Type\")\n",
    "    plt.ylabel(\"Job Count\")\n",
    "    plt.title(\"CPU-GPU Balance Analysis\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Export the analysis results to a CSV file\n",
    "# output_path = 'results/main_db_analysis.csv'\n",
    "# zero_vram_analyzer.export_results_to_csv(analysis_results, output_path)\n",
    "# print(f\"Analysis results exported to {output_path}\")\n",
    "\n",
    "# Visualize efficiency patterns\n",
    "efficiency_patterns = analysis_results[\"efficiency_patterns\"]\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=efficiency_patterns.index, y=efficiency_patterns[\"job_hours\"])\n",
    "plt.xlabel(\"Efficiency Category\")\n",
    "plt.ylabel(\"Job Hours\")\n",
    "plt.title(\"Efficiency Patterns\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923674c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply additional filtering options\n",
    "\n",
    "filtered_data = efficiency_analyzer.filter_jobs_for_analysis(\n",
    "    gpu_count_filter=1,\n",
    "    vram_constraint_filter=None,\n",
    "    allocated_vram_filter={\"min\": 0, \"max\": np.inf, \"inclusive\": False},\n",
    "    gpu_mem_usage_filter={\"min\": 0.1, \"max\": np.inf, \"inclusive\": False},\n",
    ")\n",
    "\n",
    "user_data = efficiency_analyzer.calculate_user_efficiency_metrics()\n",
    "\n",
    "# Display the filtered data\n",
    "display(user_data.head())\n",
    "\n",
    "# Identify inefficient users\n",
    "inefficient_users = efficiency_analyzer.find_inefficient_users_by_alloc_vram_efficiency(\n",
    "    efficiency_threshold=0.3, min_jobs=5\n",
    ")\n",
    "\n",
    "# Display the inefficient users\n",
    "inefficient_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c77ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot VRAM efficiency distribution (x-axis cut at 1.0)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(user_data[\"expected_value_alloc_vram_efficiency\"].dropna().clip(upper=1.0), bins=30, kde=True)\n",
    "plt.xlabel(\"VRAM Efficiency (clipped at 1.0)\")\n",
    "plt.ylabel(\"Number of Jobs\")\n",
    "plt.title(\"Distribution of VRAM Efficiency\")\n",
    "plt.xlim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0febc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with value labels for average efficiency\n",
    "if inefficient_users is not None and not inefficient_users.empty:\n",
    "    top_problematic = inefficient_users.head(10)\n",
    "    top_problematic = top_problematic.sort_values(by=\"expected_value_alloc_vram_efficiency\", ascending=True)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = sns.barplot(y=top_problematic[\"User\"], x=top_problematic[\"expected_value_alloc_vram_efficiency\"], orient=\"h\")\n",
    "    plt.xlabel(\"Average Weighted VRAM Efficiency\")\n",
    "    plt.ylabel(\"User\")\n",
    "    plt.title(\"Top 10 Problematic Users (Lowest Efficiency)\")\n",
    "    plt.xlim(0, 1.0)\n",
    "    # Add value labels\n",
    "    for bar in ax.patches:\n",
    "        ax.text(\n",
    "            bar.get_width() + 0.01,  # Position slightly to the right of the bar\n",
    "            bar.get_y() + bar.get_height() / 2,  # Center vertically\n",
    "            f\"{bar.get_width():.4f}\",  # Format the value\n",
    "            va=\"center\",  # Align vertically\n",
    "            fontsize=9,  # Font size\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "    display(top_problematic)\n",
    "else:\n",
    "    print(\"No inefficient user data available in results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e889729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by \"interactive\" using number of hours\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "hybrid_jobs = efficiency_analyzer.filter_jobs_for_analysis(\n",
    "    gpu_count_filter=None,\n",
    "    vram_constraint_filter=None,\n",
    "    allocated_vram_filter={\"min\": 0, \"max\": np.inf, \"inclusive\": False},\n",
    "    gpu_mem_usage_filter={\"min\": 0.1, \"max\": np.inf, \"inclusive\": False},\n",
    ")\n",
    "hybrid_jobs[\"gpu_memory_used_gb\"] = hybrid_jobs[\"GPUMemUsage\"] / (2**30)\n",
    "hybrid_jobs[\"allocated_vram\"] = np.where(\n",
    "    (hybrid_jobs[\"gpu_memory_used_gb\"] > 16) & (hybrid_jobs[\"GPUType\"].iloc[0] in [\"A100\", \"V100\"]),\n",
    "    32,\n",
    "    hybrid_jobs[\"allocated_vram\"],\n",
    ")\n",
    "\n",
    "# Group by job type and sum the hours\n",
    "job_type_hours = hybrid_jobs.groupby(\"Interactive\")[\"Elapsed\"].sum().reset_index()\n",
    "\n",
    "# Plot job type distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=\"Interactive\", y=\"Elapsed\", data=job_type_hours)\n",
    "\n",
    "plt.xlabel(\"Job Type (Interactive vs Non-Interactive)\")\n",
    "plt.ylabel(\"Total Elapsed Seconds\")\n",
    "plt.title(\"Total Elapsed Seconds by Job Type (Interactive vs Non-Interactive)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "ax.invert_yaxis()  # This flips the y-axis so bars grow from bottom to top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify inefficient PIs\n",
    "pi_metrics = efficiency_analyzer.calculate_pi_account_efficiency_metrics()\n",
    "inefficient_pis = efficiency_analyzer.find_inefficient_pis_weighted_by_hours(efficiency_threshold=0.3, min_jobs=5)\n",
    "\n",
    "# Display the inefficient PIs\n",
    "display(inefficient_pis.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852bca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print GPU count summary for hybrid jobs\n",
    "print(\"Unique GPU counts in hybrid jobs:\", hybrid_jobs[\"GPUs\"].unique())\n",
    "print(\"GPU count distribution in hybrid jobs:\")\n",
    "print(hybrid_jobs[\"GPUs\"].value_counts())\n",
    "print(\n",
    "    f\"Min GPUs: {hybrid_jobs['GPUs'].min()}, \"\n",
    "    f\"Max GPUs: {hybrid_jobs['GPUs'].max()}, \"\n",
    "    f\"Mean GPUs: {hybrid_jobs['GPUs'].mean():.2f}\"\n",
    ")\n",
    "\n",
    "# Visualize inefficient users (top 10 only with nonzero values)\n",
    "top_inefficient_users = inefficient_users[inefficient_users[\"Weighted_Efficiency_Contribution\"] > 0].head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=top_inefficient_users[\"Weighted_Efficiency_Contribution\"], y=top_inefficient_users[\"User\"])\n",
    "plt.xlabel(\"Weighted Efficiency Contribution\")\n",
    "plt.ylabel(\"User\")\n",
    "plt.title(\"Top 10 Inefficient Users\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first element of GPUType array and create a new field\n",
    "hybrid_jobs[\"GPUType_First\"] = hybrid_jobs[\"GPUType\"].apply(lambda x: x[0])\n",
    "# Group by GPUType_First and calculate statistics\n",
    "hybrid_jobs = efficiency_analyzer.calculate_job_efficiency_metrics(hybrid_jobs)\n",
    "print(hybrid_jobs.columns)\n",
    "gpu_stats_first = hybrid_jobs.groupby(\"GPUType_First\").agg(\n",
    "    {\n",
    "        \"alloc_vram_efficiency\": [\"mean\", \"std\"],\n",
    "        \"gpu_memory_used_gb\": [\"mean\", \"std\"],\n",
    "        \"allocated_vram\": [\"mean\", \"std\"],\n",
    "        \"job_hours\": [\"mean\", \"std\"],\n",
    "    }\n",
    ")\n",
    "print(\"Statistics grouped by GPUType_First:\")\n",
    "print(gpu_stats_first)\n",
    "\n",
    "# Plot most requested GPUs (first element)\n",
    "plt.figure(figsize=(12, 6))\n",
    "requested_gpu_counts_first = hybrid_jobs[\"GPUType_First\"].value_counts()\n",
    "sns.barplot(x=requested_gpu_counts_first.index, y=requested_gpu_counts_first.values)\n",
    "plt.title(\"Most Assigned GPUs (First Element)\")\n",
    "plt.xlabel(\"GPUType_First\")\n",
    "plt.ylabel(\"Request Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_jobs[hybrid_jobs[\"alloc_vram_efficiency\"] > 1][\n",
    "    [\n",
    "        \"JobID\",\n",
    "        \"Interactive\",\n",
    "        \"Status\",\n",
    "        \"ExitCode\",\n",
    "        \"Constraints\",\n",
    "        \"NodeList\",\n",
    "        \"gpu_count\",\n",
    "        \"GPUMemUsage\",\n",
    "        \"gpu_memory_used_gb\",\n",
    "        \"allocated_vram\",\n",
    "        \"GPUType\",\n",
    "        \"alloc_vram_efficiency\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc02246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter multi-GPU jobs\n",
    "gpu_jobs = hybrid_jobs[(hybrid_jobs[\"gpu_count\"] > 0) & (~hybrid_jobs[\"Status\"].isin([\"TIMEOUT\", \"OUT_OF_MEMORY\"]))]\n",
    "print(f\"Number of multi-GPU jobs: {len(gpu_jobs)}\")\n",
    "\n",
    "# Summarize multi-GPU job efficiency\n",
    "gpu_summary = gpu_jobs.groupby(\"gpu_count\").agg(\n",
    "    {\"alloc_vram_efficiency\": [\"mean\", \"std\"], \"job_hours\": [\"mean\", \"std\"], \"GPUMemUsage\": [\"mean\", \"std\"]}\n",
    ")\n",
    "print(\"GPU job summary:\")\n",
    "print(gpu_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017085a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize efficiency distribution for multi-GPU jobs\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"gpu_count\", y=\"alloc_vram_efficiency\", data=gpu_jobs)\n",
    "plt.title(\"Efficiency Distribution by GPU Count\")\n",
    "plt.xlabel(\"GPU Count\")\n",
    "plt.ylabel(\"Efficiency\")\n",
    "plt.show()\n",
    "gpu_jobs[gpu_jobs[\"alloc_vram_efficiency\"] > 1][\n",
    "    [\n",
    "        \"JobID\",\n",
    "        \"Status\",\n",
    "        \"ExitCode\",\n",
    "        \"Constraints\",\n",
    "        \"gpu_count\",\n",
    "        \"gpu_memory_used_gb\",\n",
    "        \"allocated_vram\",\n",
    "        \"GPUType\",\n",
    "        \"alloc_vram_efficiency\",\n",
    "    ]\n",
    "].sort_values(by=\"alloc_vram_efficiency\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot GPU Utilization vs. GPU Count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"gpu_count\", y=\"GPUMemUsage\", data=gpu_jobs)\n",
    "plt.title(\"GPU Utilization vs. GPU Count\")\n",
    "plt.xlabel(\"GPU Count\")\n",
    "plt.ylabel(\"GPU Memory Usage\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Job Duration vs. GPU Count\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"gpu_count\", y=\"job_hours\", data=gpu_jobs)\n",
    "plt.title(\"Job Duration Distribution by GPU Count\")\n",
    "plt.xlabel(\"GPU Count\")\n",
    "plt.ylabel(\"Job Duration (hours)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VRAM Efficiency Over Time\n",
    "vals = gpu_jobs.sort_values(\"Elapsed\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=\"Elapsed\", y=\"alloc_vram_efficiency\", data=vals.head(1000))\n",
    "plt.title(\"VRAM Efficiency Over Time\")\n",
    "plt.xlabel(\"Elapsed Time\")\n",
    "plt.ylabel(\"VRAM Efficiency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e540b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GPU jobs that use more CPU than they should\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter jobs where CPU usage exceeds GPU usage\n",
    "cpu_gpu_threshold = 1  # CPU usage is greater than GPU usage\n",
    "high_cpu_jobs = gpu_jobs[gpu_jobs[\"CPUMemUsage\"] > cpu_gpu_threshold * gpu_jobs[\"GPUMemUsage\"]]\n",
    "\n",
    "# Identify top users with high CPU usage relative to GPU usage\n",
    "top_users_high_cpu = high_cpu_jobs.groupby(\"User\").agg({\"CPUMemUsage\": \"sum\", \"GPUMemUsage\": \"sum\"}).reset_index()\n",
    "top_users_high_cpu[\"CPU_to_GPU_Ratio\"] = top_users_high_cpu[\"CPUMemUsage\"] / top_users_high_cpu[\"GPUMemUsage\"]\n",
    "top_users_high_cpu = top_users_high_cpu.sort_values(by=\"CPU_to_GPU_Ratio\", ascending=False).head(10)\n",
    "\n",
    "# Display the top users\n",
    "print(\"Top users where CPU usage exceeds GPU usage:\")\n",
    "print(top_users_high_cpu)\n",
    "\n",
    "# Visualize the top users\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"CPU_to_GPU_Ratio\", y=\"User\", data=top_users_high_cpu, palette=\"viridis\")\n",
    "plt.xlabel(\"CPU to GPU Usage Ratio\")\n",
    "plt.ylabel(\"User\")\n",
    "plt.title(\"Top Users with High CPU Usage Relative to GPU Usage\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the top jobs\n",
    "top_jobs_high_cpu = high_cpu_jobs.sort_values(by=\"CPUMemUsage\", ascending=False).head(10)\n",
    "print(\"Top jobs where CPU usage exceeds GPU usage:\")\n",
    "top_jobs_high_cpu[\"cpu_gpu_ratio\"] = top_jobs_high_cpu[\"CPUMemUsage\"] / top_jobs_high_cpu[\"GPUMemUsage\"]\n",
    "print(top_jobs_high_cpu[[\"JobID\", \"User\", \"CPUMemUsage\", \"GPUMemUsage\", \"cpu_gpu_ratio\"]])\n",
    "\n",
    "# Display the filtered jobs\n",
    "print(\"Jobs with high CPU usage relative to GPU usage:\")\n",
    "print(high_cpu_jobs.head())\n",
    "\n",
    "# Visualize the CPU vs GPU usage for these jobs\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    x=high_cpu_jobs[\"GPUMemUsage\"],\n",
    "    y=high_cpu_jobs[\"CPUMemUsage\"],\n",
    "    hue=high_cpu_jobs[\"Interactive\"],  # Assuming JobType is a column in gpu_df\n",
    "    palette=\"viridis\",\n",
    ")\n",
    "plt.xlabel(\"GPU Usage\")\n",
    "plt.ylabel(\"CPU Usage\")\n",
    "plt.title(\"CPU vs GPU Usage for High CPU Jobs\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
